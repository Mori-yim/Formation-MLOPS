{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02c1774",
   "metadata": {},
   "source": [
    "# TP 2 : Modélisation & Évaluation  \n",
    "## Breast Cancer Dataset\n",
    "\n",
    "---\n",
    "\n",
    "##  Description du TP\n",
    "\n",
    "**Objectif :**  \n",
    "Construire, entraîner, évaluer et comparer **plusieurs modèles de classification** afin de prédire le diagnostic du cancer du sein (malin / bénin).\n",
    "\n",
    "Ce TP met l’accent sur :\n",
    "- la comparaison rigoureuse des performances,\n",
    "- l’interprétation des résultats,\n",
    "- la préparation à un **déploiement en contexte réel**.\n",
    "\n",
    "---\n",
    "\n",
    "##  Instructions du TP\n",
    "\n",
    "### 1 Préparation des données\n",
    "- Charger le dataset prétraité issu du TP 1 (`breast_cancer_clean.csv`)\n",
    "- Séparer les données en :\n",
    "  - variables explicatives (`X`)\n",
    "  - variable cible (`y`)\n",
    "- Effectuer une séparation **train / test**\n",
    "- Appliquer la **standardisation** lorsque nécessaire\n",
    "\n",
    "---\n",
    "\n",
    "### 2 Modèles à implémenter\n",
    "Implémenter **au moins cinq (05)** algorithmes de classification parmi les suivants :\n",
    "\n",
    "- Régression Logistique\n",
    "- k-Nearest Neighbors (k-NN)\n",
    "- Support Vector Machine (SVM)\n",
    "- Arbres de décision\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- XGBoost (optionnel)\n",
    "\n",
    "---\n",
    "\n",
    "### 3️ Entraînement et optimisation\n",
    "- Entraîner chaque modèle sur le jeu d’apprentissage\n",
    "- Optimiser les hyperparamètres à l’aide de :\n",
    "  - `GridSearchCV` ou `RandomizedSearchCV`\n",
    "- Utiliser la **validation croisée**\n",
    "\n",
    "---\n",
    "\n",
    "### 4️ Évaluation des performances\n",
    "Évaluer chaque modèle à l’aide des métriques suivantes :\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "- ROC-AUC\n",
    "\n",
    "Outils d’analyse recommandés :\n",
    "- Matrice de confusion\n",
    "- Courbes ROC\n",
    "- Tableaux comparatifs des performances\n",
    "\n",
    "---\n",
    "\n",
    "### 5️ Comparaison et interprétation\n",
    "- Comparer les modèles selon plusieurs critères\n",
    "- Identifier le **meilleur modèle global**\n",
    "- Discuter des compromis entre :\n",
    "  - performance\n",
    "  - complexité\n",
    "  - interprétabilité\n",
    "\n",
    "---\n",
    "\n",
    "### 6️ Sauvegarde et réutilisation\n",
    "- Sauvegarder le **meilleur modèle** :\n",
    "  ```bash\n",
    "  best_model.joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f343863a",
   "metadata": {},
   "source": [
    "# Partie 1 : Configuration et Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chargement des données préparées\n",
    "from TP1 import X_train, X_test, y_train, y_test  # ou charger depuis fichier\n",
    "\n",
    "# 2. Modèle de baseline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Questions :\n",
    "# a) Quel est le score d'un modèle aléatoire ?\n",
    "# b) Quel est le score d'un modèle qui prédit toujours la classe majoritaire ?\n",
    "# c) Pourquoi ces baselines sont-elles importantes ?\n",
    "\n",
    "# 3. Évaluation initiale\n",
    "# Définir une fonction d'évaluation qui calcule :\n",
    "# - Accuracy, Precision, Recall, F1-Score\n",
    "# - Matrice de confusion\n",
    "# - Rapport de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a19ecc",
   "metadata": {},
   "source": [
    "# Partie 2 : Implémentation des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c0a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Implémenter 5 algorithmes différents\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Pour chaque modèle :\n",
    "# a) Initialiser avec paramètres par défaut\n",
    "# b) Entraîner sur le training set\n",
    "# c) Évaluer sur le test set\n",
    "# d) Stocker les résultats dans un DataFrame\n",
    "\n",
    "# 5. Analyse comparative\n",
    "# a) Créer un DataFrame comparatif des performances\n",
    "# b) Visualiser les résultats avec un barplot horizontal\n",
    "# c) Identifier le meilleur modèle selon le F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeec8cc",
   "metadata": {},
   "source": [
    "# Partie 3 : Validation Croisée et Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Validation croisée\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# a) Implémenter une validation croisée k=5 pour les 3 meilleurs modèles\n",
    "# b) Comparer les scores moyens et les écarts-types\n",
    "# c) Quel modèle est le plus stable ?\n",
    "\n",
    "# 7. Optimisation des hyperparamètres\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Choisir 2 modèles pour optimisation :\n",
    "# Exemple pour Random Forest :\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Questions :\n",
    "# a) Comparer GridSearchCV vs RandomizedSearchCV\n",
    "# b) Quels sont les meilleurs hyperparamètres trouvés ?\n",
    "# c) Amélioration par rapport aux paramètres par défaut ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7487048",
   "metadata": {},
   "source": [
    "# Partie 4 : Analyse Approfondie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa297a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Feature importance\n",
    "# Pour les modèles d'arbres :\n",
    "# a) Extraire et visualiser les 10 features les plus importantes\n",
    "# b) Ces features sont-elles cohérentes avec l'analyse EDA ?\n",
    "# c) Proposer une sélection de features basée sur l'importance\n",
    "\n",
    "# 9. Courbes d'évaluation\n",
    "# a) Courbe ROC et AUC pour chaque modèle\n",
    "# b) Courbe Precision-Recall (important pour classes déséquilibrées)\n",
    "# c) Learning curves pour vérifier le surapprentissage\n",
    "\n",
    "# 10. Analyse des erreurs\n",
    "# a) Quels échantillons sont mal classés par tous les modèles ?\n",
    "# b) Y a-t-il des patterns dans les erreurs ?\n",
    "# c) Proposer des améliorations possibles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258997ad",
   "metadata": {},
   "source": [
    "# Partie 5 : Pipeline de Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d639728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Création d'un pipeline complet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# a) Créer un pipeline avec preprocessing + modèle\n",
    "# b) Entraîner le pipeline sur toutes les données\n",
    "# c) Sauvegarder le modèle avec joblib\n",
    "\n",
    "# 12. Fonction de prédiction\n",
    "def predict_breast_cancer(features, model_path='best_model.joblib'):\n",
    "    \"\"\"\n",
    "    Fonction pour prédire le diagnostic d'une tumeur\n",
    "    \"\"\"\n",
    "    # Charger le modèle\n",
    "    # Prétraiter les features\n",
    "    # Faire la prédiction\n",
    "    # Retourner : diagnostic, probabilité, interprétation\n",
    "    pass\n",
    "\n",
    "# 13. Tests unitaires\n",
    "# Créer des tests pour vérifier :\n",
    "# - Format des inputs\n",
    "# - Plages de valeurs attendues\n",
    "# - Performance minimum acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026aa9ce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#  Questions d’Analyse – TP 2 (produire un document) \n",
    "## Évaluation, Interprétation & Déploiement des Modèles\n",
    "\n",
    "---\n",
    "\n",
    "##  Performance des modèles\n",
    "\n",
    "1. Quel modèle a obtenu les **meilleures performances globales** ?\n",
    "   - Sur quelles métriques vous basez-vous ?\n",
    "   - Pourquoi ce modèle performe-t-il mieux selon vous ?\n",
    "\n",
    "2. Comment les **métriques d’évaluation** (Accuracy, Precision, Recall, F1-score, ROC-AUC) diffèrent-elles entre les modèles ?\n",
    "   - Quels compromis observez-vous ?\n",
    "\n",
    "---\n",
    "\n",
    "##  Overfitting / Underfitting\n",
    "\n",
    "3. Observez-vous des signes de **surapprentissage (overfitting)** ou de **sous-apprentissage (underfitting)** ?\n",
    "   - Comment les avez-vous détectés ?\n",
    "     - comparaison train/test\n",
    "     - validation croisée\n",
    "     - courbes d’apprentissage\n",
    "\n",
    "4. Quelles **stratégies** avez-vous mises en œuvre pour réduire ces phénomènes ?\n",
    "   - régularisation\n",
    "   - validation croisée\n",
    "   - réduction de features\n",
    "   - data augmentation / rééquilibrage\n",
    "\n",
    "---\n",
    "\n",
    "##  Importance des features\n",
    "\n",
    "5. Les **features importantes** sont-elles identiques pour tous les modèles ?\n",
    "   - Comparez les méthodes basées sur :\n",
    "     - coefficients\n",
    "     - importance des arbres\n",
    "     - méthodes globales\n",
    "\n",
    "6. Est-il possible de **réduire le nombre de variables** sans perte significative de performance ?\n",
    "   - Quelles techniques avez-vous testées ?\n",
    "     - sélection de variables\n",
    "     - PCA\n",
    "     - importance cumulée\n",
    "\n",
    "---\n",
    "\n",
    "##  Cas difficiles à classer\n",
    "\n",
    "7. Quels sont les **échantillons mal classés ou incertains** ?\n",
    "   - Comment les avez-vous identifiés ?\n",
    "     - probabilités proches du seuil\n",
    "     - faux positifs / faux négatifs\n",
    "\n",
    "8. Proposez des **explications possibles** à ces erreurs :\n",
    "   - similarité morphologique\n",
    "   - bruit dans les données\n",
    "   - limites du modèle\n",
    "\n",
    "---\n",
    "\n",
    "##  Déploiement & interprétation\n",
    "\n",
    "9. Quelles sont les **considérations éthiques** liées à l’utilisation de ce modèle en milieu médical ?\n",
    "   - faux diagnostics\n",
    "   - biais\n",
    "   - responsabilité humaine\n",
    "\n",
    "10. Comment **présenteriez-vous les résultats à un médecin** ?\n",
    "    - choix des métriques\n",
    "    - visualisations adaptées\n",
    "    - interprétabilité\n",
    "\n",
    "---\n",
    "\n",
    "##  Livrables attendus\n",
    "\n",
    "- ✅ **Notebook Jupyter** avec implémentation complète et commentée\n",
    "- ✅ **Modèle entraîné sauvegardé** : `best_model.joblib`\n",
    "- ✅ **Rapport comparatif des modèles**\n",
    "  - tableaux récapitulatifs\n",
    "  - graphiques et interprétations\n",
    "- ✅ **Code de prédiction documenté**\n",
    "- ✅ **Présentation synthétique** (5 slides maximum)\n",
    "\n",
    "---\n",
    "\n",
    "##  Critères d’Évaluation\n",
    "\n",
    "###  TP 1 – /20 points\n",
    "\n",
    "| Critère              | Points | Description                                   |\n",
    "|----------------------|--------|-----------------------------------------------|\n",
    "| Complétude           | 5      | Toutes les étapes réalisées                   |\n",
    "| Qualité du code      | 4      | Code propre, commenté, conforme PEP8          |\n",
    "| Analyse statistique  | 4      | Statistiques pertinentes calculées            |\n",
    "| Visualisations       | 4      | Graphiques clairs et informatifs              |\n",
    "| Rapport écrit        | 3      | Réponses structurées et argumentées           |\n",
    "\n",
    "---\n",
    "\n",
    "###  TP 2 – /20 points\n",
    "\n",
    "| Critère               | Points | Description                                         |\n",
    "|-----------------------|--------|-----------------------------------------------------|\n",
    "| Diversité des modèles | 4      | ≥ 5 algorithmes implémentés                         |\n",
    "| Optimisation          | 4      | Hyperparamètres + validation croisée               |\n",
    "| Évaluation complète  | 4      | Métriques multiples, ROC, matrices de confusion    |\n",
    "| Analyse critique     | 4      | Interprétation, limites, justification des choix   |\n",
    "| Pipeline production  | 4      | Code robuste, tests, documentation                 |\n",
    "\n",
    "---\n",
    "\n",
    "###  Bonus – /5 points\n",
    "\n",
    "- ✅ Techniques avancées : **SMOTE, PCA**\n",
    "- ✅ Interfac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb678e2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
